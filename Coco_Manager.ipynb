{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tEjnYkIBbJB"
      },
      "source": [
        "# Coco Manager\n",
        "\n",
        "\n",
        "* Reads the annotations from a JSON file (i.e. `instances_train2017.json`)\n",
        "\n",
        "* Reads the images either from the disk (i.e. from `COCO/train2017/` folder),\n",
        "or by downloading them from `coco_url`s provided in annotations JSON file\n",
        "\n",
        "* Selects all of the Coco classes (81 classes total), or produces a subset to scale according to the project (i.e. if `classes = ['person']`, it will find all of the images with a person, and delete all other bounding boxes and masks from them)\n",
        "\n",
        "* Scales the images to have a particular shape, gathers images into batches\n",
        "\n",
        "* Shows the image alongside the semantic masks of the objects\n",
        "\n",
        "* Fits easily into a `DataLoader` (see `Usage_Coco_Manager.ipynb`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNaiRbbbwM2H"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torchvision as tv\n",
        "import torch.nn as nn\n",
        "\n",
        "import numpy as np\n",
        "from pycocotools.coco import COCO\n",
        "from PIL import Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "import itertools\n",
        "import os\n",
        "from typing import Dict, Tuple, List\n",
        "\n",
        "from skimage.morphology import disk, closing\n",
        "from skimage import io\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDqzKDFWwM40"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Coco_Manager( torch.utils.data.Dataset ):\n",
        "    \n",
        "    def __init__( self,\n",
        "                 local_imgs_path:   str=None,\n",
        "                 path_ann:          str=None,\n",
        "                 coco:              COCO=None,\n",
        "                 output_size:       Tuple[int]=None):\n",
        "        \n",
        "        self.version = 1.3\n",
        "        \n",
        "        self.local_imgs_path = local_imgs_path\n",
        "        self.coco = coco if coco else COCO( path_ann )\n",
        "        self.ids = list(sorted(self.coco.imgs.keys()))\n",
        "        print( f'(Full Set) Images found: {len(self.ids)}' )\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.possible_colors = self.create_colors()\n",
        "        np.random.shuffle(self.possible_colors)\n",
        "\n",
        "\n",
        "    '''Generate colors for the masks'''\n",
        "    def create_colors( self ) -> List[Tuple[int]]:\n",
        "        perm = lambda choices, n: list(itertools.product(*[choices]*n))\n",
        "        colors = perm([64*i for i in range(4)], 3) \n",
        "        return [list(rgb) for rgb in colors[1:]]\n",
        "\n",
        "\n",
        "    '''Choose a subset of image IDs'''\n",
        "    def make_subset( self,\n",
        "                    classes: List,\n",
        "                    intersection: bool=False ) -> List:\n",
        "\n",
        "        catIds = self.coco.getCatIds(catNms=classes)\n",
        "\n",
        "        if intersection:\n",
        "            true_ids = self.coco.getImgIds(catIds=catIds)\n",
        "        else:\n",
        "            true_ids = []\n",
        "            for catId in catIds:\n",
        "                true_ids = true_ids + self.coco.getImgIds(catIds=[catId])\n",
        "            true_ids = list(set(true_ids))\n",
        "                \n",
        "        len_new = len(true_ids)\n",
        "        len_old = len(self.ids)\n",
        "        \n",
        "        print( f'(Subset) Images found: {len_new}/{len_old} ({round(100*len_new/len_old, 2)}%)' )\n",
        "\n",
        "        self.ids = true_ids\n",
        "        self.catIds = catIds\n",
        "        self.classes = classes\n",
        "    \n",
        "\n",
        "    '''Get an image from coco_url, if images themselves are not on disk'''\n",
        "    def download_image( self, id: int ) -> Tuple[np.array, List]:\n",
        "        \n",
        "        imgIds = self.coco.getImgIds(imgIds = id)\n",
        "        try:\n",
        "            img = self.coco.loadImgs(imgIds[np.random.randint(0,len(imgIds))])[0]\n",
        "            annIds = self.coco.getAnnIds( id )\n",
        "            ann = self.coco.loadAnns( annIds )\n",
        "        except:\n",
        "            print( f\"No image found with ID: {id}\" )\n",
        "            return None, None\n",
        "        for i in range(len(ann)):\n",
        "            ann[i].update({'category_name': self.coco.loadCats(ann[i]['category_id'])})\n",
        "\n",
        "        img = np.array(io.imread(img['coco_url']))\n",
        "        return img, ann\n",
        "\n",
        "\n",
        "\n",
        "    '''DataLoader outputs Tuple[ image, dictionary with annotations ]'''\n",
        "    def collate_fn( self, data: Tuple[ torch.Tensor, Dict ]\n",
        "                  ) -> Tuple[ torch.Tensor, List[Dict] ]:\n",
        "        \n",
        "        imgs = [sample[0] for sample in data]\n",
        "        anns = [sample[1] for sample in data]\n",
        "        imgs = torch.stack( imgs )\n",
        "        return {'imgs':imgs, 'anns':anns}\n",
        "     \n",
        "    \n",
        "    def __len__( self ):\n",
        "        return len( self.ids )\n",
        "\n",
        "\n",
        "    def transform( self, img ) -> Tuple[torch.Tensor, Tuple[int]]:\n",
        "\n",
        "        '''PIL Image to pytorch Tensor'''\n",
        "        img = torch.Tensor(img)\n",
        "        \n",
        "        '''Pad the image if it's smaller than output_size'''\n",
        "        if self.output_size != None:\n",
        "            target_w, target_h = self.output_size\n",
        "            w, h = img.size()[0], img.size()[1]           \n",
        "            w_pad = (target_w - w) \n",
        "            h_pad = (target_h - h)\n",
        "            crop_origin = (0, 0)\n",
        "            if (w_pad > 0) or (h_pad > 0):\n",
        "                img, crop_origin = self.center_padding( img,\n",
        "                                          w_pad if (w_pad>0) else 0,\n",
        "                                          h_pad if (h_pad>0) else 0)\n",
        "            \n",
        "            if (w_pad < 0) or (h_pad < 0):                \n",
        "                img = self.resize(img)\n",
        "                ratio = (target_w/w, target_h/h)\n",
        "            else:\n",
        "                ratio = (1, 1)\n",
        "        \n",
        "        return img, crop_origin, ratio\n",
        "\n",
        "\n",
        "\n",
        "    '''Reshape the image to fit the output_size'''\n",
        "    def resize( self, img: torch.Tensor ) -> torch.Tensor:\n",
        "        resize = tv.transforms.Resize(size = self.output_size, interpolation=tv.transforms.InterpolationMode.NEAREST)\n",
        "        T = torch.transpose\n",
        "        img_resized = T(T(img, 0, 2), 1, 2)\n",
        "        img_resized = resize(img_resized)\n",
        "        img_resized = T(T(img_resized, 0, 1), 1, 2)\n",
        "        # print(f'Resized: img.shape = {img.shape} -> img_resized.shape = {img_resized.shape}')\n",
        "        return img_resized\n",
        "\n",
        "\n",
        "    '''Add zero-padding to match output_size'''\n",
        "    def center_padding( self,\n",
        "                        img:  torch.Tensor,\n",
        "                        w_pad:    int,\n",
        "                        h_pad:    int   ) -> torch.Tensor:\n",
        "\n",
        "        left_pad = w_pad // 2\n",
        "        right_pad = w_pad - left_pad\n",
        "        top_pad = h_pad // 2\n",
        "        bottom_pad = h_pad - top_pad\n",
        "\n",
        "        imgpad = nn.functional.pad(\n",
        "            input=img,\n",
        "            pad=(0, 0, top_pad, bottom_pad, left_pad, right_pad),\n",
        "            mode=\"constant\",\n",
        "            value = 0 )\n",
        "        # print( f'Added zero-padding: {img.size()} -> {imgpad.size()}' )\n",
        "        return imgpad, (top_pad, left_pad)\n",
        "\n",
        "\n",
        "\n",
        "    '''Fetch the image and annotations, transform and add to the batch'''\n",
        "    def __getitem__( self, index: int ):\n",
        "        \n",
        "        '''Dataset ID to Coco ID: works in one of two modes: with local images and without'''\n",
        "        img_id = self.ids[index]\n",
        "        if self.local_imgs_path == None:\n",
        "            img, coco_annotations = self.download_image( img_id )\n",
        "        else:\n",
        "            ann_ids = self.coco.getAnnIds( imgIds=img_id )\n",
        "            coco_annotations = self.coco.loadAnns(ann_ids)\n",
        "            path = self.coco.loadImgs(img_id)[0]['file_name']\n",
        "            img = Image.open(os.path.join(self.local_imgs_path, path))\n",
        "\n",
        "        '''Image Transformations'''\n",
        "        img, crop_origin, ratio = self.transform( img )\n",
        "        img /= 255\n",
        "\n",
        "        '''If the subset is used, erase all unnecessary annotations'''\n",
        "        if self.catIds:\n",
        "            coco_annotations = [obj for obj in coco_annotations if obj['category_id'] in self.catIds ]\n",
        "\n",
        "        '''Object Labels'''\n",
        "        num_objs = len(coco_annotations)\n",
        "        for i in range(num_objs):\n",
        "            coco_annotations[i].update({'category_name': self.coco.loadCats(coco_annotations[i]['category_id'])})\n",
        "        obj_labels = [ ob['category_name'][0]['name'] for ob in coco_annotations ]\n",
        "\n",
        "        '''Bounding Boxes and Masks'''\n",
        "        '''Coco [xmin, ymin, width, height] -> torch [xmin, ymin, xmax, ymax]'''\n",
        "        boxes = []\n",
        "        masks = []\n",
        "        \n",
        "        for i in range(num_objs):\n",
        "\n",
        "            box = self.translate_box(\n",
        "                coco_annotations[i]['bbox'],\n",
        "                crop_origin,\n",
        "                ratio )\n",
        "            \n",
        "            mask = self.coco.annToMask(coco_annotations[i])\n",
        "            masks.append( mask )\n",
        "            boxes.append( box )\n",
        "            \n",
        "\n",
        "        '''Bounding boxes areas'''\n",
        "        areas = [ coco_annotations[i]['area'] for i in range(num_objs) ]\n",
        "\n",
        "\n",
        "        '''Merge binary masks of the same class\n",
        "        for example: 224x224x3 image with 2 classes -> np.array([224, 224, 2])\n",
        "        From the greatest mask to the smallest'''\n",
        "        stack_shape = (masks[0].shape[0], masks[0].shape[1], len(self.classes))\n",
        "        masks_stack = np.zeros(stack_shape, dtype='uint8')\n",
        "\n",
        "        for i in reversed(np.argsort(np.array(areas))):\n",
        "            label = obj_labels[i]\n",
        "            mask = masks[i]\n",
        "\n",
        "            layer = self.classes.index( label )\n",
        "            masks_stack[ :, :, layer ] |= mask\n",
        "            \n",
        "        masks_stack, _, _ = self.transform( masks_stack )\n",
        "\n",
        "        '''Image Annotations Dictionary'''\n",
        "        annotation = {}\n",
        "        annotation[\"boxes\"] = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        annotation[\"masks\"] = masks_stack\n",
        "        annotation[\"labels\"] = obj_labels\n",
        "        annotation[\"coco_id\"] = torch.tensor([img_id])\n",
        "        annotation[\"areas\"] = torch.as_tensor(areas, dtype=torch.float32)\n",
        "        \n",
        "        # ???\n",
        "        # print( f'COCO: img.size() = {img.size()}' )\n",
        "        # if img.size()[0] == 1:\n",
        "        #     img = torch.stack([img for _ in range(3)])\n",
        "\n",
        "        # print( f'Number of Objects: {num_objs}' )\n",
        "        return img, annotation\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    '''Shows the image and the semantic masks'''\n",
        "    def show( self, img: np.array, anns: Dict ) -> None:\n",
        "        \n",
        "        with plt.style.context('dark_background'):\n",
        "        \n",
        "            fig, ax = plt.subplots(ncols=2, figsize=(18, 15), dpi=110)\n",
        "            \n",
        "            bboxes = anns['boxes']\n",
        "            labels = anns['labels']\n",
        "            obj_num = bboxes.size()[0]\n",
        "\n",
        "            possible_colors = self.possible_colors.copy()\n",
        "            colors = {label: np.array(possible_colors.pop(0)) for label in self.classes}\n",
        "\n",
        "            '''Draw the boxes on the original image'''\n",
        "            default_color = 'lawngreen'\n",
        "            for i in range(obj_num):\n",
        "\n",
        "                '''Shift the label color to brighter hues'''\n",
        "                label = labels[i]\n",
        "                color = (colors[label] / 255 + 1.5) / (1.5+1) \n",
        "\n",
        "                bbox = bboxes[i]\n",
        "                rect = mpatches.Rectangle(\n",
        "                    (bbox[0], bbox[1]), bbox[4], bbox[5], fill=False, edgecolor=default_color, linewidth=2)\n",
        "                circle = mpatches.Circle(\n",
        "                    (bbox[0]+torch.div(bbox[4], 2, rounding_mode='floor' ),\n",
        "                     bbox[1]+torch.div(bbox[5], 2, rounding_mode='floor' )), color=default_color)\n",
        "                ax[0].add_patch( rect )\n",
        "                ax[0].add_patch( circle )\n",
        "                ax[0].text( bbox[0], bbox[1]-5, labels[i], fontdict={'color':default_color} )\n",
        "                ax[1].text( bbox[0], bbox[1]-5, labels[i], fontdict={'color':color} )\n",
        "                \n",
        "            '''Draw image'''\n",
        "            img = img.numpy()\n",
        "            ax[0].imshow( img )\n",
        "            ax[0].set_title(f'Original Image (Coco ID: {anns[\"coco_id\"].item()})', y=1.04)\n",
        "            \n",
        "            '''Fill the empty canvas with masks'''\n",
        "            canvas = np.zeros((img.shape[0], img.shape[1], 3), dtype='uint8')\n",
        "            masks = anns['masks']\n",
        "            \n",
        "            for layer, label in enumerate(self.classes):\n",
        "                color = colors[label]\n",
        "                mask = masks[:,:,layer].numpy()\n",
        "                for i in range(3):\n",
        "                    canvas[:,:,i] += (mask * color[i]).astype(np.uint8) # // 3\n",
        "\n",
        "            # for i in range(3):\n",
        "            #     canvas[:,:,i] = closing(canvas[:,:,i], disk(3))\n",
        "            \n",
        "            ax[1].imshow(canvas)\n",
        "            ax[1].set_title('Mask from COCO annotations', y=1.04)\n",
        "\n",
        "\n",
        "\n",
        "    def translate_box( self, org_bbox, crop_origin, ratio ):\n",
        "        \n",
        "        x0, y0 = crop_origin\n",
        "        ratio_h, ratio_w = ratio\n",
        "\n",
        "        xmin = int((org_bbox[0] + x0) * ratio_w)\n",
        "        ymin = int((org_bbox[1] + y0) * ratio_h)\n",
        "\n",
        "        width  = int(org_bbox[2] * ratio_w)\n",
        "        height = int(org_bbox[3] * ratio_h)\n",
        "        xmax   = xmin + width\n",
        "        ymax   = ymin + height\n",
        "\n",
        "        return [xmin, ymin, xmax, ymax, width, height]\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Coco_Manager.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}